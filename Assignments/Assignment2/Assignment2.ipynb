{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPfsaEyPJgbluJwYjABXbS6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hany606/PAI_Fall21IU/blob/main/Assignments/Assignment2/Assignment2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S6-m3S7wV1sX",
        "outputId": "7b13d2c2-80f7-4b39-9c0e-2a982c2bc50d"
      },
      "source": [
        "!pip install spacy"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: spacy in /usr/local/lib/python3.7/dist-packages (2.2.4)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (3.0.5)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.19.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.23.0)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.0.5)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.8.2)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (4.62.0)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (7.4.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy) (57.4.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: importlib-metadata>=0.20 in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy) (4.6.4)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy) (3.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy) (3.7.4.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2021.5.30)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cndB1uUTV71H",
        "outputId": "cdf0561f-10f5-4920-f8c9-62f58a87f9ba"
      },
      "source": [
        "# Import libraries\n",
        "import nltk\n",
        "import spacy\n",
        "from spacy import displacy\n",
        "import en_core_web_sm\n",
        "from nltk import Tree\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "    - [ ] deftemplate   : \n",
        "    \n",
        "    ```\n",
        "    Cat template has properties of color, age, and name.\n",
        "    (deftemplate cat\n",
        "        (slot color) (slot age) (slot name))\n",
        "    ```\n",
        "    \n",
        "    - [ ] defrule:\n",
        "    \n",
        "    ```\n",
        "    If there exists cat named Bob then there exists a cat named Tom.\n",
        "    (defrule rule1\n",
        "        (cat (name “Bob”)) => (assert (cat (name “Tom”))))\n",
        "    ```\n",
        "\n",
        "    - [ ] assert:\n",
        "    ```\n",
        "    There exists a cat with the name Bob.\n",
        "    (assert (cat (name “Bob”)))\n",
        "    ```\n",
        "\"\"\"\n",
        "\n",
        "help = \"Type \\n- 'exit' to go out from the program\\n- 'help' to print the help menu\\n- Enter any other command to translate it to CLIPS\"\n",
        "\n",
        "\n",
        "\n",
        "class NLP:\n",
        "  def __init__(self, nlp_loader=en_core_web_sm):\n",
        "    self._nlp = nlp_loader.load()\n",
        "    self.command_keywords = {\"template\": [\"template\", \"struct\", \"definition\", \"property\", \"define\"],\n",
        "                             \"rule\": [\"if\"],\n",
        "                             \"assert\": [\"assert\", \"exist\"]}\n",
        "\n",
        "    self.command_root_keywords = {\"template\": [\"have\"],\n",
        "                                  \"rule\": [\"if\"],\n",
        "                                  \"assert\": [\"be\"]}\n",
        "\n",
        "  def nlp(self, inp):\n",
        "    return self._nlp(inp)\n",
        "\n",
        "  def teach_me(self):\n",
        "    print(\"?? Teach me ??\")\n",
        "    print(\"\\tTeaching me a new keyword for a specific command of CLIPS from the list (template, rule, assert)\\n\")\n",
        "\n",
        "    new_key = input(f\"?? Enter the new key that you used for the previous commnand\\n\\tMost probably one from {self.all_dict['subjects']}\\n?? Enter: \")\n",
        "    while True:\n",
        "      command = input(\"?? Now input the command: \").lower()\n",
        "      if(command in self.command_keywords.keys()):\n",
        "        self.command_keywords[command].append(new_key)\n",
        "        break\n",
        "      elif(command == \"exit\"):\n",
        "        print(\"Did not learn new thing :(\")\n",
        "        return\n",
        "      else:\n",
        "        print(\"Enter the command from the list (template, rule, assert)\")\n",
        "    print(f\"Now, the command {command} has a new keyword: {new_key}\")\n",
        "\n",
        "\n",
        "  def search(self, root):\n",
        "    # Check the root\n",
        "    for command_key in self.command_root_keywords.keys():\n",
        "      for command in self.command_root_keywords[command_key]:\n",
        "        if(command == root.lemma_): # if we have found a similar\n",
        "          if(command_key == \"template\"):\n",
        "            return self.clips_template(command)\n",
        "\n",
        "          elif(command_key == \"rule\"):\n",
        "            return self.clips_rule(command)\n",
        "\n",
        "          elif(command_key == \"assert\"):\n",
        "            return self.clips_assert(command)\n",
        "\n",
        "    # Search accross the registered keywords for the commands\n",
        "    for command_key in self.command_keywords.keys():\n",
        "      for command in self.command_keywords[command_key]:\n",
        "        if(command in self.all_dict[\"lemma_dict\"].keys()): # if we have found a similar\n",
        "          if(command_key == \"template\"):\n",
        "            return self.clips_template(command)\n",
        "\n",
        "          elif(command_key == \"rule\"):\n",
        "            return self.clips_rule(command)\n",
        "\n",
        "          elif(command_key == \"assert\"):\n",
        "            return self.clips_assert(command)\n",
        "\n",
        "    return None\n",
        "\n",
        "\n",
        "  def _get_attributes(self):\n",
        "    # Recursively search for things that are related to actions(ROOT) pos_=NOUN and \n",
        "    # [to_nltk_tree(sent.root).pretty_print() for sent in doc.sents]\n",
        "\n",
        "    # For now only get all the pos_: [pobjs, conj]\n",
        "    attributes = []\n",
        "    for token_text in self.all_dict[\"tokens_dict\"].keys():\n",
        "      if(self.all_dict[\"tokens_dict\"][token_text].dep_ in [\"pobjs\", \"conj\"] and\\\n",
        "         self.all_dict[\"tokens_dict\"][token_text].pos_ in [\"NOUN\"]):\n",
        "        attributes.append(token_text)\n",
        "\n",
        "    # attributes = [\"name\"]\n",
        "    return attributes\n",
        "\n",
        "  def _get_template_name(self, command):\n",
        "    # token.head.text\n",
        "    template_name = self.all_dict[\"tokens_dict\"][list(self.all_dict[\"tokens_dict\"].keys())[0]]  # Default\n",
        "    # Iterate all over the tokens to find the template name that is attached to the keyword for template command and at the same time is noun\n",
        "    # Return the last word that comforms with these conditions\n",
        "    for token_text in self.all_dict[\"tokens_dict\"].keys():\n",
        "      # print(token_text,\\\n",
        "      #       self.all_dict[\"tokens_dict\"][token_text].head.text in self.all_dict[\"lemma_dict\"][command],\\\n",
        "      #       self.all_dict[\"tokens_dict\"][token_text].pos_ ==\"NOUN\",\\\n",
        "      #       self.all_dict[\"tokens_dict\"][token_text].dep_ in [\"compound\", \"ROOT\"])\n",
        "      if(\\\n",
        "        #  self.all_dict[\"tokens_dict\"][token_text].head.text in self.all_dict[\"lemma_dict\"][command] and\\\n",
        "         self.all_dict[\"tokens_dict\"][token_text].pos_ == \"NOUN\" and\\\n",
        "         self.all_dict[\"tokens_dict\"][token_text].dep_ in [\"compound\", \"ROOT\", \"nsubj\"] or\\\n",
        "         (self.all_dict[\"tokens_dict\"][token_text].pos_ == \"PROPN\" and\\\n",
        "         self.all_dict[\"tokens_dict\"][token_text].dep_ in [\"compound\"])):\n",
        "        template_name = token_text\n",
        "        break    \n",
        "    return template_name\n",
        "\n",
        "  def clips_template(self, command):\n",
        "    # print(\"Template CLIPS TODO\")\n",
        "    # print(self.all_dict)\n",
        "    template_name = self._get_template_name(command)\n",
        "    attributes = self._get_attributes()\n",
        "    # print(template_name, attributes)\n",
        "    clips_attributes = [f\"(slot {a})\" for a in attributes]\n",
        "    clips = f\"(deftemplate {template_name}\\n\\t{' '.join(clips_attributes)})\"\n",
        "    # print(clips)\n",
        "    return clips\n",
        "\n",
        "  def clips_rule(self, command):\n",
        "    print(\"Rule CLIPS TODO\")\n",
        "    print(self.all_dict)\n",
        "    clips = \"\"\n",
        "    return clips\n",
        "\n",
        "\n",
        "\n",
        "  def clips_assert(self, command):\n",
        "    print(\"Assert CLIPS TODO\")\n",
        "    asserted_obj = self._get_asserted_obj()\n",
        "        \n",
        "    clips = \"\"\n",
        "    return clips\n",
        "\n",
        "  def to_nltk_tree(self, node):\n",
        "      if node.n_lefts + node.n_rights > 0:\n",
        "          return Tree(node.orth_, [self.to_nltk_tree(child) for child in node.children])\n",
        "      else:\n",
        "          return node.orth_\n",
        "\n",
        "\n",
        "  def process(self, user_input, render=False):\n",
        "      # dictionaries: keys are the text and the value is the token itself\n",
        "      # subjects = {}\n",
        "      # actions = {}\n",
        "      # objects = {}\n",
        "      # tokens_dict = {}\n",
        "      # lemma_dict = {} # key is the lemma and the value is the text\n",
        "      self.all_dict = {\"subjects\": {}, # dictionaries: keys are the text and the value is the token itself\n",
        "                        \"actions\": {}, \n",
        "                        \"objects\": {}, \n",
        "                        \"tokens_dict\": {},\n",
        "                        \"lemma_dict\": {}, # Here: key is the lemma and the value is the text\n",
        "                        \"doc\":None\n",
        "                        }\n",
        "\n",
        "\n",
        "      doc = self.nlp(user_input)\n",
        "      self.all_dict[\"doc\"] = doc\n",
        "      # Store the subjs, acts, objs, and all the tokens in dictionaries\n",
        "      for token in doc:\n",
        "        token_text = token.text.lower()\n",
        "        role = token.dep_\n",
        "        if(role == \"nsubj\"):\n",
        "          self.all_dict[\"subjects\"][token_text] = token\n",
        "        elif(role == \"ROOT\"):\n",
        "          self.all_dict[\"actions\"][token_text] = token\n",
        "        elif(role == \"dobj\"):\n",
        "          self.all_dict[\"objects\"][token_text] = token\n",
        "\n",
        "        self.all_dict[\"tokens_dict\"][token_text] = token\n",
        "        if(token.lemma_ in self.all_dict[\"lemma_dict\"]):\n",
        "          self.all_dict[\"lemma_dict\"][token.lemma_].append(token.text)\n",
        "        else:\n",
        "          self.all_dict[\"lemma_dict\"][token.lemma_] = [token.text]\n",
        "        \n",
        "\n",
        "      # ---------------------------------------------------------------------------------------------\n",
        "      # Visualization\n",
        "      if(render):\n",
        "        for token in doc:\n",
        "            print(\"Word = {}, Lemma = {}, PoS/Tag = {}/{}, Role = {} to [{}]\".format(\n",
        "                    token.text, token.lemma_, token.pos_, token.tag_, token.dep_, token.head.text))\n",
        "        print(\"Display\")\n",
        "        displacy.render(doc, jupyter=True, style='dep')\n",
        "        self.to_nltk_tree(list(doc.sents)[0].root).pretty_print()\n",
        "\n",
        "          # [self.to_nltk_tree(sent.root).pretty_print() for sent in doc.sents]\n",
        "      # ---------------------------------------------------------------------------------------------\n",
        "\n",
        "\n",
        "\n",
        "      # Search for the keywords for the commands\n",
        "      search_result = self.search(list(doc.sents)[0].root)\n",
        "      if(search_result is not None):\n",
        "        return search_result\n",
        "      self.teach_me()\n",
        "      return -1\n",
        "\n",
        "nlp = NLP()\n",
        "template_test = [\"The cat has color, age, name, and eyes.\",\n",
        "                 \"Cat has color, age, name, and eyes.\",\n",
        "                 \"The cat template has properties of color, age, name, and eyes.\",\n",
        "                 \"Cat template has properties of color, age, name, and eyes.\",\n",
        "                 \"The cat defined by color, age, name, and eyes.\"]\n",
        "res = [(nlp.process(temp, render=False), temp) for temp in template_test]\n",
        "for r in res:\n",
        "  print(r[1])\n",
        "  print(r[0])\n",
        "  print(\"-----------\")\n",
        "# print()\n",
        "# print(nlp.process(\"If there exists cat named Bob then there exists a cat named Tom.\", render=True))\n",
        "# print(nlp.process(\"There is a cat with the name Bob\", render=True))"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The cat has color, age, name, and eyes.\n",
            "(deftemplate cat\n",
            "\t(slot age) (slot name) (slot eyes))\n",
            "-----------\n",
            "Cat has color, age, name, and eyes.\n",
            "(deftemplate Cat\n",
            "\t(slot age) (slot name) (slot eyes))\n",
            "-----------\n",
            "The cat template has properties of color, age, name, and eyes.\n",
            "(deftemplate cat\n",
            "\t(slot age) (slot name) (slot eyes))\n",
            "-----------\n",
            "Cat template has properties of color, age, name, and eyes.\n",
            "(deftemplate cat\n",
            "\t(slot age) (slot name) (slot eyes))\n",
            "-----------\n",
            "The cat defined by color, age, name, and eyes.\n",
            "(deftemplate cat\n",
            "\t(slot age) (slot name) (slot eyes))\n",
            "-----------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IJA3uE6JV9IJ"
      },
      "source": [
        "# Create UI\n",
        "print(help)\n",
        "while True:\n",
        "    user_input = input(\"Input English (1 sentence per time)\\n>> \")\n",
        "    # user_input = user_input.lower()\n",
        "\n",
        "    if(user_input.lower() == \"exit\"):\n",
        "        print(\"Good Bye!\")\n",
        "        exit()\n",
        "    elif(user_input.lower() == \"help\"):\n",
        "        print(help)\n",
        "    \n",
        "    clips_command = process(user_input, render=True)\n",
        "    print(f\"CLIPS\\n>> {clips_command}\")\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}